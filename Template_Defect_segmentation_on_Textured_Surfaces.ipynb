{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Template_Defect_segmentation_on_Textured_Surfaces.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "S-fSL1r2fQ7Z"
      },
      "cell_type": "markdown",
      "source": [
        "We will use the Industrial Optical Inspection Dataset. \n",
        "The blocks given below will help you copy and unzip the data from google drive.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The dataset description can be found here : https://hci.iwr.uni-heidelberg.de/node/3616"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DymbI5OJIuFF"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Colab\n",
        "Set the Runtime to GPU from the menu on the top left of this webpage\n",
        "\n",
        "Importing data to Google Colab"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zDP8dGDEfHM2",
        "outputId": "292fbfa9-216a-4bf5-8fbb-6ef3b1f56aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3on7wPL6mBF2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fc9f7b5-1a05-4594-d2b1-369046180786"
      },
      "cell_type": "code",
      "source": [
        "# Copy data to google colab from google drive and unzip\n",
        "# This may take 1-2 minutes\n",
        "!cp gdrive/My\\ Drive/optical_data.zip .\n",
        "!unzip optical_data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  optical_data.zip\n",
            "replace data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w_-5AVwxm7d5",
        "outputId": "3da003e6-f0db-4040-91c9-6bdceca203ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# You should be able to see 7 Classes here\n",
        "!ls data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class1\tClass2\tClass3\tClass4\tClass5\tClass6\tClass7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HkvMl2Mt-BrB"
      },
      "cell_type": "markdown",
      "source": [
        "Sample Output : Class1 Class2\tClass3\tClass4\tClass5\tClass6\tClass7"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "H-GSOCv7ImGM"
      },
      "cell_type": "markdown",
      "source": [
        "# Main Notebook"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2p453M9kewcU",
        "outputId": "041518a2-32ff-430d-89c7-b079e5ceecdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from random import shuffle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.python.lib.io import file_io\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import cv2\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "P6Rilzb2Lnhz"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PFUOmRq1hChy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Not all data in the dataset has defects. We only use the images which have defects\n",
        "# This function takes the dataset_type as a parameter. You can pass \"Train\" or \"Test\"\n",
        "# as argument to get the appropriate dataset\n",
        "def load_data(dataset_type=\"Train\"):\n",
        "    file_list = {}\n",
        "    defect_map = {}\n",
        "    file_name = []\n",
        "    file_mask = []\n",
        "    count = 0\n",
        "    num_classes = 6\n",
        "\n",
        "    data_dir = \"data\"\n",
        "    for x in range(1, num_classes + 1):\n",
        "        path = os.path.join(os.path.join(data_dir, \"Class\" + str(x)), dataset_type)\n",
        "        df = pd.read_fwf(path + \"/Label/Labels.txt\")\n",
        "        count = 0\n",
        "        for i in range(0, len(df)):\n",
        "            curr_file = path + \"/\" + str(df.iloc[i][2])\n",
        "            if (df.iloc[i][1] == 1):\n",
        "                file_list[curr_file] = path + \"/Label/\" + str(df.iloc[i][4])\n",
        "                defect_map[curr_file] = 1\n",
        "            else:\n",
        "                fnametest = str(df.iloc[i][2]).split(\".\")\n",
        "                file_list[curr_file] = str(path + \"/Label/\" + fnametest[0] + \"_label.PNG\")\n",
        "                defect_map[curr_file] = 0\n",
        "\n",
        "    items = list(file_list.keys())\n",
        "    shuffle(items)\n",
        "    for key in items:\n",
        "        if ((not os.path.exists(key)) or (not os.path.exists(file_list[key]))):\n",
        "            # print (\"Missing mask for \", key)\n",
        "            continue\n",
        "\n",
        "        if defect_map[key] == 1:\n",
        "            file_name.append(key)\n",
        "            file_mask.append(file_list[key])\n",
        "        elif count < 80 * num_classes:\n",
        "            file_name.append(key)\n",
        "            file_mask.append(file_list[key])\n",
        "            count = count + 1\n",
        "\n",
        "    return file_name, file_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YMvNNG8nLq1N"
      },
      "cell_type": "markdown",
      "source": [
        "Since the dataset is so large that it cannot fit into memory, we will need to use generator functions to iteratively load the dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0AO5Je2_iyjI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is generator class to process data in batches and send them for training\n",
        "class Surface_Generator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, image_filenames, labels, batch_size, test=False):\n",
        "        self.image_filenames, self.labels = image_filenames, labels\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    # return the total number of batches you have i.e., total_files/batch_size\n",
        "    def __len__(self):\n",
        "        return len(self.labels) // self.batch_size\n",
        "\n",
        "    # this function is called for every mini-batch to get the images/masks for that mini-batch\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        image_arr = []\n",
        "        mask_arr = []\n",
        "        # Open a batch of images and their corresponding masks using cv2.imread\n",
        "        # resize them to 512x512x1 and return an np.array of images and masks\n",
        "        image_arr = [resize(cv2.imread(z, 0), (512, 512, 1)) for z in batch_x]\n",
        "        mask_arr = [resize(cv2.imread(z, 0), (512, 512, 1)) for z in batch_y]\n",
        "\n",
        "        return np.array(image_arr).astype(np.float32), np.array(mask_arr).astype(np.float32)\n",
        "    \n",
        "    # for testing we need to get the list of all true masks\n",
        "    # this function should return all the labels in the dataset set \n",
        "    # we will call this function only for the \"Test\" dataset\n",
        "    def get_all_masks(self):\n",
        "        mask_arr = [resize(cv2.imread(z, 0), (512, 512, 1)) for z in self.labels]\n",
        "        return np.array(mask_arr).astype(np.float32)\n",
        "\n",
        "      \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dt-r8DWtiXb8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Since we already have a split for training and test set,\n",
        "# we just need to split training set to get a validation set\n",
        "\n",
        "# Load training data\n",
        "X, Y = load_data(\"Train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yCCf5m26iZ4-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69aee82d-772c-4024-94d9-84843dbc3c9a"
      },
      "cell_type": "code",
      "source": [
        "# Split the original training data to get training and validation set\n",
        "# to get X_train, X_val, y_train, y_val\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2)\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(740,) (740,) (186,) (186,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pzVG7OlIKzPC"
      },
      "cell_type": "markdown",
      "source": [
        "The output shape after the split should be \n",
        "(740,) (740,) (186,) (186,)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TuWAS7_Qt7xw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9132043a-dee3-49db-ee71-0db52dbc39be"
      },
      "cell_type": "code",
      "source": [
        "# Free memory\n",
        "import gc\n",
        "del X\n",
        "del Y\n",
        "gc.collect()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Pg95L-qULPUY"
      },
      "cell_type": "markdown",
      "source": [
        "# Metrics\n",
        "\n",
        "Use keras.backend to calculate dice coefficient metric and dice coefficient loss function.\n",
        "\n",
        "Recall that dice_coeff = 2 \\* intersection / union\n",
        "\n",
        "We add a smoothing parameter and modify the formula to\n",
        "\n",
        "dice_coeff = 2 \\* (intersection + smooth) / (union + smooth)\n",
        "\n",
        "Our objective is to make dice_coeff as close to 1.0 as possible. \n",
        "Define and use the appropriate loss function."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JwdFSKS-jB8S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dice Coefficient metric\n",
        "def dice_coef(y_true, y_pred):\n",
        "#     https://stackoverflow.com/questions/45961428/make-a-custom-loss-function-in-keras\n",
        "    smooth = 1\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Dice Coefficient loss\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Pynq8QkQMQfV"
      },
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "U-net architeture has proved to be very powerful for segmentation tasks.\n",
        "\n",
        "We will be creating a Unet model based on the paper : \n",
        "\n",
        "[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf)\n",
        "\n",
        "---\n",
        "\n",
        "A picture of the architecture we plan to use is provided in the project description pdf.\n",
        "\n",
        "We will create a Convolutional block module to help us build the model.\n",
        "\n",
        "Each convolutional block module will contain two trainable layers. \n",
        "\n",
        "Each layer will be a Convolution operation followed by batch normalization with relu activation.\n",
        "\n",
        "\n",
        "\n",
        "The U-net architecture has a contracting path, a convolution and then an expansive path.\n",
        "\n",
        "We will use instances of the convolutional block to create the contracting and expansive path."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NmHn08ChjWNq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2DTranspose, Dropout, Activation, BatchNormalization, UpSampling2D, Concatenate\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "# Create a 2D convolution block. We will use multiple instances of this block to build our U-net model\n",
        "# This block will contain two layers. \n",
        "# Each layer will be a Convolution operation followed by batch normalization with relu activation \n",
        "def conv2d_block(input_tensor, n_filters, kernel_size):\n",
        "    # first layer\n",
        "    # Create a Conv2D layer with n_filters and a kernel of dimension : kernel_size x kernel_size. \n",
        "    # Use same padding and he_normal initializer\n",
        "    conv1 = Conv2D(n_filters, kernel_size, padding = 'same', kernel_initializer = 'he_normal')(input_tensor)\n",
        "    \n",
        "    # add a BatchNormalization layer\n",
        "    bn1 = BatchNormalization()(conv1)\n",
        "        \n",
        "    # Add a relu non-linearity (keras.layers.Activation)\n",
        "    rel1 = Activation('relu')(bn1)\n",
        "    \n",
        "    # second layer\n",
        "    conv2 = Conv2D(n_filters, kernel_size, padding = 'same', kernel_initializer = 'he_normal')(rel1)\n",
        "    bn2 = BatchNormalization()(conv2)\n",
        "    rel2 = Activation('relu')(bn2)\n",
        "    \n",
        "    # return the output tensor\n",
        "    return rel2\n",
        "\n",
        "\n",
        "def get_unet_model(n_filters=16, dropout_prob=0.5, kernel_size=3):\n",
        "    input_img = Input((512, 512, 1))\n",
        "    \n",
        "    # contracting path\n",
        "    # create a convolutional block with input_img as the input tensor and n_filters\n",
        "    c1 = conv2d_block(input_img, n_filters, kernel_size)\n",
        "\n",
        "    # apply a 2d maxpooling with a pool size of 2x2\n",
        "    p1 = MaxPooling2D(pool_size = (2,2))(c1)\n",
        "\n",
        "    # add a dropout. Since this the input, set the dropout rate to 0.5 * dropout_prob\n",
        "    p1 = Dropout(0.5 * dropout_prob) (p1)\n",
        "\n",
        "    # create another convolutional block. this time use p1 as input tensor and twice the n_filters\n",
        "    # repeat the same maxpool and dropout but set dropout rate to dropout_prob this time\n",
        "    c2 = conv2d_block(p1, 2 * n_filters, kernel_size)\n",
        "    p2 = MaxPooling2D(pool_size = (2,2))(c2)\n",
        "    p2 = Dropout(dropout_prob)(p2)\n",
        "\n",
        "    # create another block with maxpool and dropout with 4 x n_filters\n",
        "    c3 = conv2d_block(p2, 4 * n_filters, kernel_size)\n",
        "    p3 = MaxPooling2D(pool_size = (2,2))(c3)\n",
        "    p3 = Dropout(dropout_prob)(p3)\n",
        "\n",
        "    # create another block with maxpool and dropout with 8 x n_filters\n",
        "    c4 = conv2d_block(p3, 8 * n_filters, kernel_size)\n",
        "    p4 = MaxPooling2D(pool_size = (2,2))(c4)\n",
        "    p4 = Dropout(dropout_prob)(p4)\n",
        "    \n",
        "\n",
        "    # This is the layer where we combine the contractive and expansive paths\n",
        "    # create a convolutional block with 16 x n_filters. No pooling/dropout this time\n",
        "    c5 = conv2d_block(p4, 16 * n_filters, kernel_size)\n",
        "    \n",
        "    # Expansive path\n",
        "\n",
        "    # We will create a similar structure as the contracting path but instead of \n",
        "    # convolutional operation, we will use Deconvolution operations\n",
        "\n",
        "    # Create a Conv2DTranspose layer (deconvolution) with 8 x n_filters, kernel_size, \n",
        "    # 2x2 strides and same padding\n",
        "    u6 = Conv2DTranspose(8 * n_filters, kernel_size, strides = (2,2), padding = \"same\", kernel_initializer = 'he_normal')(c5)\n",
        "    \n",
        "    # Concatenate u6 and c4 using keras.layers.concatenate\n",
        "    u6 = keras.layers.concatenate([u6, c4])\n",
        "    \n",
        "    # dropout\n",
        "    u6 = Dropout(dropout_prob)(u6)\n",
        "    \n",
        "    # create a convolutional block with 8 x n_filters\n",
        "    c6 = conv2d_block(u6, 8*n_filters, kernel_size)\n",
        "    \n",
        "\n",
        "    # Create a similar module as previous, deconv, concatenate, dropout, conv2d_block\n",
        "    # Please ensure that the number of filters you use match the n_filters of \n",
        "    # the layer you are concatenating with\n",
        "    u7 = Conv2DTranspose(4 * n_filters, kernel_size, strides = (2,2), padding = \"same\", kernel_initializer = 'he_normal')(c6)\n",
        "    u7 = keras.layers.concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout_prob)(u7)\n",
        "    c7 = conv2d_block(u7, 4 * n_filters, kernel_size)\n",
        "    \n",
        "    # Create a similar module as previous, deconv, concatenate, dropout, conv2d_block\n",
        "    # YOUR CODE HERE\n",
        "    u8 = Conv2DTranspose(2 * n_filters, kernel_size, strides = (2,2), padding = \"same\", kernel_initializer = 'he_normal')(c7) \n",
        "    u8 = keras.layers.concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout_prob)(u8)\n",
        "    c8 = conv2d_block(u8, 2 * n_filters, kernel_size)\n",
        "\n",
        "\n",
        "    # Create a similar module as previous, deconv, concatenate, dropout, conv2d_block\n",
        "    u9 = Conv2DTranspose(n_filters, kernel_size, strides = (2,2), padding = \"same\", kernel_initializer = 'he_normal')(c8)\n",
        "    u9 = keras.layers.concatenate([u9, c1])\n",
        "    u9 = Dropout(dropout_prob)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters, kernel_size)\n",
        "\n",
        "    # apply a 1x1 convolution on c9 to get an output with a single channel\n",
        "    # This is the final model output. We want the pixel values in the mask to be\n",
        "    # either 0 or 1. Choose an activation function which can give values in that\n",
        "    # range.\n",
        "    c9 = Conv2D(1, kernel_size, padding=\"same\", strides = (1,1), kernel_initializer = 'he_normal', input_shape = c9.get_shape())(c9)\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9JBg48_qiQ_R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_name = \"unet\"\n",
        "model = get_unet_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "motKXf_TiUKg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "num_epochs = 50\n",
        "# Compile the model\n",
        "model.compile(loss=dice_coef_loss, optimizer=Adam(lr=0.0055), metrics=[dice_coef])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewQjQjWyqq-e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create generator objects for training and validation\n",
        "num_training_samples = len(X_train)\n",
        "num_validation_samples = len(X_val)\n",
        "training_batch_generator = Surface_Generator(X_train, y_train, batch_size)\n",
        "validation_batch_generator = Surface_Generator(X_val, y_val, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_otO9PPuq2ED",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OPTIONAL\n",
        "# callbacks for saving models and early stopping\n",
        "checkpointer = ModelCheckpoint(model_name + \"/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor=dice_coef, verbose=1,\n",
        "                               save_best_only=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "63cNn_B6q4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1292
        },
        "outputId": "b2e4df27-c95f-40c0-c8bf-9a7d284c247b"
      },
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "# This will take ~1.5-2 minutes per epoch on a GPU\n",
        "stmillis = int(round(time.time() * 1000))\n",
        "history = model.fit_generator(generator=training_batch_generator,\n",
        "                    steps_per_epoch=(num_training_samples // batch_size),\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_batch_generator,\n",
        "                    validation_steps=(num_validation_samples // batch_size),\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=5,\n",
        "                    max_queue_size=1,\n",
        "                    callbacks=[checkpointer, early_stopping])\n",
        "endmillis = int(round(time.time() * 1000))\n",
        "print(\"Time taken: \", endmillis - stmillis)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "92/92 [==============================] - 107s 1s/step - loss: 0.9053 - dice_coef: 0.0947 - val_loss: 0.9630 - val_dice_coef: 0.0370\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 92s 997ms/step - loss: 0.7404 - dice_coef: 0.2596 - val_loss: 0.9595 - val_dice_coef: 0.0405\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 92s 1s/step - loss: 0.5848 - dice_coef: 0.4152 - val_loss: 0.9597 - val_dice_coef: 0.0403\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 92s 997ms/step - loss: 0.5786 - dice_coef: 0.4214 - val_loss: 0.9505 - val_dice_coef: 0.0495\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 92s 1s/step - loss: 0.5294 - dice_coef: 0.4706 - val_loss: 0.6930 - val_dice_coef: 0.3070\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 92s 1000ms/step - loss: 0.5132 - dice_coef: 0.4868 - val_loss: 0.5840 - val_dice_coef: 0.4160\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 92s 998ms/step - loss: 0.5174 - dice_coef: 0.4826 - val_loss: 0.6523 - val_dice_coef: 0.3477\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 92s 997ms/step - loss: 0.5559 - dice_coef: 0.4441 - val_loss: 0.9365 - val_dice_coef: 0.0635\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 92s 1s/step - loss: 0.5338 - dice_coef: 0.4662 - val_loss: 0.9447 - val_dice_coef: 0.0553\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 92s 1s/step - loss: 0.5102 - dice_coef: 0.4898 - val_loss: 0.8907 - val_dice_coef: 0.1093\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 92s 1000ms/step - loss: 0.4994 - dice_coef: 0.5006 - val_loss: 0.8445 - val_dice_coef: 0.1555\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 92s 996ms/step - loss: 0.4927 - dice_coef: 0.5073 - val_loss: 0.4795 - val_dice_coef: 0.5205\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 91s 994ms/step - loss: 0.4890 - dice_coef: 0.5110 - val_loss: 0.4598 - val_dice_coef: 0.5402\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 91s 994ms/step - loss: 0.4756 - dice_coef: 0.5244 - val_loss: 0.7257 - val_dice_coef: 0.2743\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 91s 992ms/step - loss: 0.5155 - dice_coef: 0.4845 - val_loss: 0.8859 - val_dice_coef: 0.1141\n",
            "Epoch 16/50\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.4817 - dice_coef: 0.5183Epoch 16/50\n",
            "92/92 [==============================] - 91s 994ms/step - loss: 0.4794 - dice_coef: 0.5206 - val_loss: 0.4429 - val_dice_coef: 0.5571\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 91s 994ms/step - loss: 0.4689 - dice_coef: 0.5311 - val_loss: 0.4667 - val_dice_coef: 0.5333\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 91s 990ms/step - loss: 0.5883 - dice_coef: 0.4117 - val_loss: 0.8921 - val_dice_coef: 0.1079\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 91s 993ms/step - loss: 0.6035 - dice_coef: 0.3965 - val_loss: 0.8551 - val_dice_coef: 0.1449\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 91s 993ms/step - loss: 0.6017 - dice_coef: 0.3983 - val_loss: 0.6582 - val_dice_coef: 0.3418\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 91s 992ms/step - loss: 0.4756 - dice_coef: 0.5244 - val_loss: 0.6218 - val_dice_coef: 0.3782\n",
            "Epoch 22/50\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.4590 - dice_coef: 0.5410\n",
            "92/92 [==============================] - 91s 994ms/step - loss: 0.4573 - dice_coef: 0.5427 - val_loss: 0.5646 - val_dice_coef: 0.4354\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 91s 993ms/step - loss: 0.4503 - dice_coef: 0.5497 - val_loss: 0.4058 - val_dice_coef: 0.5942\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 91s 994ms/step - loss: 0.4488 - dice_coef: 0.5512 - val_loss: 0.4453 - val_dice_coef: 0.5547\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 91s 993ms/step - loss: 0.4494 - dice_coef: 0.5506 - val_loss: 0.3960 - val_dice_coef: 0.6040\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 92s 996ms/step - loss: 0.4464 - dice_coef: 0.5536 - val_loss: 0.4495 - val_dice_coef: 0.5505\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 91s 991ms/step - loss: 0.4497 - dice_coef: 0.5503 - val_loss: 0.4852 - val_dice_coef: 0.5148\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 92s 996ms/step - loss: 0.4594 - dice_coef: 0.5406 - val_loss: 0.4510 - val_dice_coef: 0.5490\n",
            "Epoch 29/50\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.4416 - dice_coef: 0.5584\n",
            "92/92 [==============================] - 91s 991ms/step - loss: 0.4476 - dice_coef: 0.5524 - val_loss: 0.4005 - val_dice_coef: 0.5995\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 92s 998ms/step - loss: 0.4442 - dice_coef: 0.5558 - val_loss: 0.5255 - val_dice_coef: 0.4745\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 92s 999ms/step - loss: 0.4244 - dice_coef: 0.5756 - val_loss: 0.6035 - val_dice_coef: 0.3965\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 91s 989ms/step - loss: 0.4349 - dice_coef: 0.5651 - val_loss: 0.4009 - val_dice_coef: 0.5991\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 92s 1000ms/step - loss: 0.4313 - dice_coef: 0.5687 - val_loss: 0.4091 - val_dice_coef: 0.5909\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 91s 994ms/step - loss: 0.4066 - dice_coef: 0.5934 - val_loss: 0.5893 - val_dice_coef: 0.4107\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 91s 993ms/step - loss: 0.4082 - dice_coef: 0.5918 - val_loss: 0.4051 - val_dice_coef: 0.5949\n",
            "Epoch 00035: early stopping\n",
            "Time taken:  3225371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3brG4OSvidg-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1065
        },
        "outputId": "573d9b35-5700-4a8c-cdd8-67e2f1be8b21"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights\n",
        "model.save(model_name + \".h5\")\n",
        "\n",
        "# # Save model config as json\n",
        "# model_json = model.to_json()\n",
        "# with open(model_name + \".json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "\n",
        "# Persist the model to your google drive [VERY IMPORTANT]\n",
        "!cp unet.* gdrive/My\\ Drive/"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-b48ae0a05fcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# # Save model config as json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model_json = model.to_json()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# with open(model_name + \".json\", \"w\") as json_file:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_json_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Not JSON Serializable: ?"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gyQIv8vP-Bvr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78e2d8d6-9be9-497a-b2e9-c2489ec3c2d6"
      },
      "cell_type": "code",
      "source": [
        "# Confirm if model did get saved\n",
        "!ls -ltr gdrive/My\\ Drive/unet*"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'gdrive/My Drive/unet*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oXpPThkeAp30",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In case you wish to load your saved model\n",
        "!cp gdrive/My\\ Drive/unet* .\n",
        "\n",
        "model.load_weights(\"unet.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hfVKLvOSinhR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "889bbc25-2284-43e2-df26-c6123ed95109"
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# Load test data in X_test and y_test\n",
        "X_test, y_test = load_data(\"Test\")\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "print (X_test.shape, y_test.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(454,) (454,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "T6Z-UydF9wFR"
      },
      "cell_type": "markdown",
      "source": [
        "Output shape should be (454,) (454,)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xDvVIz7eVDeJ"
      },
      "cell_type": "markdown",
      "source": [
        "[OPTIONAL] Shuffle and select 25 elements for quick testing\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JW2AcXfX4ok1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# np.random.seed = 629\n",
        "# p = np.random.permutation(len(X_test))\n",
        "# X_test = X_test[p]\n",
        "# y_test = y_test[p]\n",
        "\n",
        "# X_test = X_test[:25]\n",
        "# y_test = y_test[:25]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WUDhmrOnzd1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27b8d170-4f16-42d0-d9a5-ed5b50b9bf36"
      },
      "cell_type": "code",
      "source": [
        "# Predict using model.predict_generator().\n",
        "test_data_generator = Surface_Generator(X_test, y_test, 1, test=True)\n",
        "num_test_samples = len(y_test)\n",
        "y_pred = model.predict_generator(generator=test_data_generator,\n",
        "                                verbose=1,\n",
        "                                steps=(num_test_samples),\n",
        "                                max_queue_size=1,\n",
        "                                use_multiprocessing=True,\n",
        "                                workers=5)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "454/454 [==============================] - 33s 72ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "y2yJe5T40aws",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fc9d9bb-683f-4990-d88b-b2ec20d619f9"
      },
      "cell_type": "code",
      "source": [
        "# y_true will have the true masks\n",
        "y_true = test_data_generator.get_all_masks()\n",
        "print (\"Dice coefficient on test data: \", K.get_value(dice_coef(y_true, y_pred)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dice coefficient on test data:  0.6363648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rq51uM6fUoo8"
      },
      "cell_type": "markdown",
      "source": [
        "The dice coefficient on test data should be close to 0.7\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TVuJ6cCTfeXB"
      },
      "cell_type": "markdown",
      "source": [
        "Visulaizing the mask for a random image"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kn447ZCDfAUd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert sigmoid outputs to binary class labels\n",
        "y_pred[30][y_pred[30] >= 0.5] = 1\n",
        "y_pred[30][y_pred[30] < 0.5] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HmUZiALBJcie",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "7536fb97-da07-4ed4-b0de-8e4d8b4d3698"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(y_true[30][:,:,0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng6SOwSCpYzBI6vwfWy/OgsGn60UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pn5Fkv9-JDiX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "bff357f7-bf94-4281-9e0c-1f3ac5b2d499"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(y_pred[30][:,:,0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "isCQ_Cxpehpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b04b309-7e97-46a4-f837-85377e315c74"
      },
      "cell_type": "code",
      "source": [
        "# Dice coefficient on this example\n",
        "K.get_value(dice_coef(y_true[30], y_pred[30]))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.55745834"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Z9PebgnFu3Yu"
      },
      "cell_type": "markdown",
      "source": [
        "Data augmentation techniques almost always help in improving the performance of deep learning models.\n",
        "\n",
        "\n",
        "Try beating the result obtained above by doing some kind of data augmentation and leave the code/results in the jupyter file.\n",
        "\n",
        "Provide the dice coefficient obtained on the new model trained with data augmentation.\n",
        "\n",
        "---\n",
        "\n",
        "# Experimentation Zone\n",
        "You may write any custom code here. The data augmentation part will be evaluated from this region."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mFL6rvc4yUPp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}